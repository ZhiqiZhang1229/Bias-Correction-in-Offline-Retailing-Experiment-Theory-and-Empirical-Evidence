{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6c27192f",
   "metadata": {
    "id": "6c27192f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\zhang\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\scipy\\__init__.py:155: UserWarning: A NumPy version >=1.18.5 and <1.26.0 is required for this version of SciPy (detected version 1.26.4\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import statsmodels.api as sm\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f14efbb6",
   "metadata": {
    "id": "f14efbb6"
   },
   "source": [
    "# Data Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "56819b49-b3bb-4d32-ad88-a458e7ee142a",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_USER = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "47ff42b4-0dd7-4555-bfbc-c1d6a7c65bbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_Product = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b42efd20-8c8f-4675-aa1a-9a2534ee60ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "treatment_percentage = 0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bce9a174-68e6-47f3-ad2f-966cc2698e25",
   "metadata": {},
   "outputs": [],
   "source": [
    "discount = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fc24047e-fa23-40ae-b761-5f0d1fbe595e",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_continuous_feature_multiplier = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "338e9f4b-a5a7-47a9-b06d-5216d077594e",
   "metadata": {},
   "outputs": [],
   "source": [
    "prod_continuous_feature_multiplier = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9083308b",
   "metadata": {
    "id": "9083308b"
   },
   "outputs": [],
   "source": [
    "# Set constants\n",
    "USER_Cont_FEATURES = 2*user_continuous_feature_multiplier\n",
    "USER_Dicr_FEATURES = 3\n",
    "\n",
    "Product_Cont_FEATURES = 3*prod_continuous_feature_multiplier\n",
    "Product_Dicr_FEATURES = 2\n",
    "OUTSIDE_OPTION_UTILITY = 0\n",
    "utilities = torch.zeros(NUM_USER, NUM_Product)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "442d9dd4",
   "metadata": {
    "id": "442d9dd4"
   },
   "outputs": [],
   "source": [
    "def generate_features(N, C, D):\n",
    "    continuous_features = np.zeros((N, C))\n",
    "    for i in range(C):\n",
    "        continuous_features[:, i] = np.random.uniform(0,1,size=N)\n",
    "    binary_features = np.random.randint(0, 2, (N, D))\n",
    "    return np.hstack((continuous_features, binary_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cb84b940",
   "metadata": {
    "id": "cb84b940"
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.init as init\n",
    "\n",
    "class UtilityDNN(nn.Module):\n",
    "    def __init__(self, user_features, product_features):\n",
    "        super(UtilityDNN, self).__init__()\n",
    "        self.fc1 = nn.Linear(user_features + product_features, 1)\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class PriceSensitivityDNN(nn.Module):\n",
    "    def __init__(self, user_features):\n",
    "        super(PriceSensitivityDNN, self).__init__()\n",
    "        self.fc1 = nn.Linear(user_features, 128)\n",
    "        self.fc2 = nn.Linear(128, 32)\n",
    "        self.fc3 = nn.Linear(32, 8)\n",
    "        self.fc4 = nn.Linear(8, 1)\n",
    "\n",
    "\n",
    "        nn.init.uniform_(self.fc1.weight, a=-0.5, b=0.5)\n",
    "        nn.init.uniform_(self.fc2.weight, a=-0.5, b=0.5)\n",
    "        nn.init.uniform_(self.fc3.weight, a=-0.5, b=0.5)\n",
    "        nn.init.uniform_(self.fc4.weight, a=-0.5, b=0.5)\n",
    "        nn.init.uniform_(self.fc1.bias, a=-0.5, b=0.5)\n",
    "        nn.init.uniform_(self.fc2.bias, a=-0.5, b=0.5)\n",
    "        nn.init.uniform_(self.fc3.bias, a=-0.5, b=0.5)\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = torch.relu(self.fc3(x))\n",
    "        x = self.fc4(x)\n",
    "        return torch.abs(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0e26f6da",
   "metadata": {
    "id": "0e26f6da"
   },
   "outputs": [],
   "source": [
    "def utility_model(x_user, X_product, price, user_randomization, prod_randomization,pair_utility_model,price_sensitivity_model,gumbel_noise):\n",
    "    num_users = x_user.shape[0]\n",
    "    num_products = X_product.shape[0]\n",
    "    \n",
    "\n",
    "    price_sensitivities = price_sensitivity_model(x_user)\n",
    "\n",
    "    for i in range(num_users):\n",
    "\n",
    "        for j in range(num_products):\n",
    "            # Determine if the user and product are in the treatment group\n",
    "            is_user_treated = (user_randomization[i] == 1)\n",
    "            is_product_treated = (prod_randomization[j] == 1)\n",
    "\n",
    "            # Adjust price based on the experiment conditions\n",
    "            adjusted_price = price[j] * discount if is_user_treated or is_product_treated else price[j]\n",
    "            combined_features = torch.cat((x_user[i], X_product[j]), 0)\n",
    "            utility_from_dnn = pair_utility_model(combined_features)\n",
    "            price_effect = price_sensitivities[i] * adjusted_price\n",
    "\n",
    "            utilities[i, j] = utility_from_dnn - price_effect + gumbel_noise[i,j]\n",
    "\n",
    "    return utility_from_dnn,price_effect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "22bf01fa",
   "metadata": {
    "id": "22bf01fa"
   },
   "outputs": [],
   "source": [
    "def make_decision(utilities):\n",
    "    num_users = utilities.shape[0]\n",
    "    decisions = torch.zeros(num_users, dtype=torch.long)  \n",
    "    for i in range(num_users):\n",
    "        max_utility, chosen_product = torch.max(utilities[i], dim=0)\n",
    "\n",
    "        # Compare the maximum utility with the outside option (utility = 0)\n",
    "        if max_utility <= 0:\n",
    "            decisions[i] = -1 \n",
    "        else:\n",
    "            decisions[i] = chosen_product \n",
    "\n",
    "    return decisions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3a7b9061",
   "metadata": {
    "id": "3a7b9061"
   },
   "outputs": [],
   "source": [
    "def calculate_revenue(decisions, prices):\n",
    "    total_revenue = 0.0\n",
    "\n",
    "    # Iterate over each decision and add the corresponding product price to total revenue\n",
    "    for i, decision in enumerate(decisions):\n",
    "        if decision != -1:  # Check if the decision is not the outside option\n",
    "            total_revenue += prices[decision].item()  # Add the price of the chosen product\n",
    "\n",
    "    return total_revenue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "be800ea9",
   "metadata": {
    "id": "be800ea9"
   },
   "outputs": [],
   "source": [
    "X_user = generate_features(NUM_USER,USER_Cont_FEATURES, USER_Dicr_FEATURES)\n",
    "X_product = generate_features(NUM_Product, Product_Cont_FEATURES, Product_Dicr_FEATURES)\n",
    "price = np.random.uniform(0.5 ,1, NUM_Product)\n",
    "\n",
    "X_user = torch.from_numpy(X_user).float()\n",
    "X_product = torch.from_numpy(X_product).float()\n",
    "price = torch.from_numpy(price).float()\n",
    "gumbel_dist = torch.distributions.Gumbel(0, 1)\n",
    "gumbel_noise = gumbel_dist.sample((NUM_USER, NUM_Product))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "13b1ab05",
   "metadata": {
    "id": "13b1ab05"
   },
   "outputs": [],
   "source": [
    "pair_utility_model = UtilityDNN(X_user.shape[1], X_product.shape[1])\n",
    "price_sensitivity_model = PriceSensitivityDNN(X_user.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a148e1c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def utility_model_batched(x_user, X_product, price, user_randomization, prod_randomization, pair_utility_model, price_sensitivity_model, gumbel_noise, batch_size=10):\n",
    "    num_users = x_user.shape[0]\n",
    "    num_products = X_product.shape[0]\n",
    "    decisions = torch.zeros(num_users, dtype=torch.long)  # Initialize decision array\n",
    "\n",
    "    # Convert numpy arrays to tensors if necessary\n",
    "    if isinstance(user_randomization, np.ndarray):\n",
    "        user_randomization = torch.from_numpy(user_randomization).to(torch.bool)\n",
    "    if isinstance(prod_randomization, np.ndarray):\n",
    "        prod_randomization = torch.from_numpy(prod_randomization).to(torch.bool)\n",
    "    if isinstance(price, np.ndarray):\n",
    "        price = torch.from_numpy(price)\n",
    "\n",
    "    # Compute price sensitivities outside the batch loop\n",
    "    price_sensitivities = price_sensitivity_model(x_user)\n",
    "\n",
    "    # Iterate over users in batches\n",
    "    for i in range(0, num_users, batch_size):\n",
    "        batch_end = min(i + batch_size, num_users)  # Define the end of the batch\n",
    "        batch_indices = slice(i, batch_end)  # Slice for batch indexing\n",
    "\n",
    "        # Repeat the product features and price for each user in the batch\n",
    "        batch_user_features = x_user[batch_indices].unsqueeze(1).expand(-1, num_products, -1)\n",
    "        batch_prod_features = X_product.unsqueeze(0).expand(batch_end - i, -1, -1)\n",
    "        batch_price = price.unsqueeze(0).expand(batch_end - i, -1)\n",
    "\n",
    "        # Handle treatment adjustments in batch\n",
    "        batch_user_treatment = user_randomization[batch_indices].unsqueeze(1).expand(-1, num_products) == 1\n",
    "        batch_prod_treatment = prod_randomization.unsqueeze(0).expand(batch_end - i, -1) == 1\n",
    "        batch_adjusted_price = torch.where(batch_user_treatment | batch_prod_treatment, batch_price * discount, batch_price)\n",
    "\n",
    "        # Combine user and product features\n",
    "        combined_features = torch.cat((batch_user_features, batch_prod_features), dim=2)\n",
    "\n",
    "        # Compute utilities using the neural network in a batch\n",
    "        utility_from_dnn = pair_utility_model(combined_features.view(-1, combined_features.shape[-1])).view(batch_end - i, num_products)\n",
    "        price_effect = price_sensitivities[batch_indices] * batch_adjusted_price\n",
    "        batch_utilities = utility_from_dnn - price_effect + gumbel_noise[batch_indices]\n",
    "        max_utilities, chosen_products = torch.max(batch_utilities, dim=1)\n",
    "\n",
    "        # Compare the maximum utility with the outside option (utility = 0)\n",
    "        outside_option = -1 * torch.ones_like(chosen_products, dtype=torch.long)  # Match dimension and dtype\n",
    "        decisions[batch_indices] = torch.where(max_utilities > 0, chosen_products, outside_option)\n",
    "\n",
    "    return decisions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c97381ec",
   "metadata": {
    "id": "c97381ec"
   },
   "source": [
    "# GTE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c74c9652",
   "metadata": {
    "id": "c74c9652"
   },
   "source": [
    "## All treated scenario: all products are discounted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8620e2f7",
   "metadata": {
    "id": "8620e2f7"
   },
   "outputs": [],
   "source": [
    "user_randomization = np.random.choice([0,1], NUM_USER, p=[1, 0])\n",
    "prod_randomization = np.random.choice([0,1], NUM_Product, p=[0, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a69429d2",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a69429d2",
    "outputId": "da77f021-0faf-424d-91be-088437608bf6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decisions per user (product index or -1 for outside option):\n",
      " tensor([2, 2, 9,  ..., 2, 2, 3])\n"
     ]
    }
   ],
   "source": [
    "decisions_all_treat=utility_model_batched(X_user, X_product,price, user_randomization, prod_randomization, \n",
    "                                          pair_utility_model, price_sensitivity_model, gumbel_noise, batch_size=10)\n",
    "\n",
    "print(\"Decisions per user (product index or -1 for outside option):\\n\", decisions_all_treat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e3b7df52-fdc0-46a9-ad64-9119957d6e3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11\n"
     ]
    }
   ],
   "source": [
    "all_num_unique = torch.unique(decisions_all_treat).numel()\n",
    "print(all_num_unique)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e8748518-f99d-47ae-a031-7b89fbbfa669",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2)\n",
      "tensor(1157)\n",
      "tensor(956)\n",
      "tensor(939)\n",
      "tensor(1133)\n",
      "tensor(969)\n",
      "tensor(876)\n",
      "tensor(1004)\n",
      "tensor(966)\n",
      "tensor(1037)\n",
      "tensor(961)\n"
     ]
    }
   ],
   "source": [
    "for i in range(-1,10):\n",
    "    print(torch.sum(decisions_all_treat==i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f59995c9",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 162
    },
    "id": "f59995c9",
    "outputId": "b6b193fc-3ab4-4e76-8096-49dfeae0a46d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total revenue from sales when all products are discounted: $1393.10\n"
     ]
    }
   ],
   "source": [
    "total_revenue_all_treated = calculate_revenue(decisions_all_treat, price*discount)\n",
    "print(f\"Total revenue from sales when all products are discounted: ${total_revenue_all_treated:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c86abbc5",
   "metadata": {},
   "source": [
    "## All control scenario: all products remain the original price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "34e8b6df",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 358
    },
    "id": "34e8b6df",
    "outputId": "846dbf7a-920f-4c54-d79f-1b527ec86ff3",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decisions per user (product index or -1 for outside option):\n",
      " tensor([2, 2, 9,  ..., 2, 2, 3])\n",
      "Total Revenue from Sales: $6841.47\n"
     ]
    }
   ],
   "source": [
    "user_randomization = np.random.choice([0,1], NUM_USER, p=[1, 0])\n",
    "prod_randomization = np.random.choice([0,1], NUM_Product, p=[1, 0])\n",
    "\n",
    "decisions_all_control =utility_model_batched(X_user, X_product,price, user_randomization, prod_randomization, \n",
    "                                          pair_utility_model, price_sensitivity_model, gumbel_noise, batch_size=10)\n",
    "\n",
    "print(\"Decisions per user (product index or -1 for outside option):\\n\", decisions_all_control)\n",
    "total_revenue_all_control = calculate_revenue(decisions_all_control, price)\n",
    "print(f\"Total Revenue from Sales: ${total_revenue_all_control:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2e3c0837",
   "metadata": {
    "id": "2e3c0837"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Revenue Difference (ALLTreated - ALLControl): $-5448.37\n"
     ]
    }
   ],
   "source": [
    "revenue_difference = total_revenue_all_treated - total_revenue_all_control\n",
    "print(f\"Revenue Difference (ALLTreated - ALLControl): ${revenue_difference:.2f}\")\n",
    "# print(f\"Revenue Relative Difference (ALLTreated - ALLControl)/AllControl: {100*revenue_difference/total_revenue_all_control:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "Sp6U7JOV1vEi",
   "metadata": {
    "id": "Sp6U7JOV1vEi"
   },
   "outputs": [],
   "source": [
    "true = revenue_difference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0ec3bca",
   "metadata": {
    "id": "d0ec3bca"
   },
   "source": [
    "## product randomization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4cbbd718",
   "metadata": {
    "id": "4cbbd718"
   },
   "outputs": [],
   "source": [
    "def calculate_product_revenue(decisions, prices, prod_randomization):\n",
    "    revenue_treated = 0.0\n",
    "    revenue_control = 0.0\n",
    "\n",
    "    # Iterate over each user's decision\n",
    "    for user_index, decision in enumerate(decisions):\n",
    "        if decision != -1:  # If the user chose a product\n",
    "            product_price = prices[decision].item()  # Get the price of the chosen product\n",
    "\n",
    "            # Check if the product was in the treatment or control group\n",
    "            if prod_randomization[decision] == 1:\n",
    "                revenue_treated += product_price\n",
    "            else:\n",
    "                revenue_control += product_price\n",
    "\n",
    "    return revenue_treated, revenue_control"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "402ee3f8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "402ee3f8",
    "outputId": "17e270ca-c5e5-4e92-fd2f-2c675eb2fbf8"
   },
   "outputs": [],
   "source": [
    "utilities = torch.zeros(NUM_USER, NUM_Product)\n",
    "user_randomization = np.random.choice([0,1], NUM_USER, p=[1, 0])\n",
    "prod_randomization = np.random.choice([0,1], NUM_Product, p=[1-treatment_percentage, treatment_percentage])\n",
    "# prod_randomization = np.random.choice([0,1], NUM_Product, p=[1, ])\n",
    "decisions_product_randomization =utility_model_batched(X_user, X_product,price, user_randomization, prod_randomization, \n",
    "                                          pair_utility_model, price_sensitivity_model, gumbel_noise, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "022d9af1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "022d9af1",
    "outputId": "9f338893-e1f9-4c6a-945c-408a2e5b6f57"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Revenue from Treated Products: $1065.88\n",
      "Revenue from Control Products: $1626.50\n",
      "Revenue Difference (Treated - Control) by naive DIM: $-6800.13\n"
     ]
    }
   ],
   "source": [
    "revenue_treated, revenue_control = calculate_product_revenue(decisions_product_randomization, price-price*(1-discount)*prod_randomization, prod_randomization)\n",
    "naive = revenue_treated/treatment_percentage - revenue_control/(1-treatment_percentage)\n",
    "print(f\"Revenue from Treated Products: ${revenue_treated:.2f}\")\n",
    "print(f\"Revenue from Control Products: ${revenue_control:.2f}\")\n",
    "print(f\"Revenue Difference (Treated - Control) by naive DIM: ${naive:.2f}\")\n",
    "# print(f\"Revenue Relative Difference (ALLTreated - ALLControl)/AllControl: {100*revenue_difference/revenue_control:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5df4b9eb",
   "metadata": {},
   "source": [
    "## Prepare training and testing data given experiment data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "wUgBFRaYHK7-",
   "metadata": {
    "id": "wUgBFRaYHK7-"
   },
   "outputs": [],
   "source": [
    "X_user_1, X_user_2, decision_1, decision_2 = train_test_split(\n",
    "X_user, decisions_product_randomization, test_size=1/2, random_state=3407)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8bd5975d-53cb-45c6-90e2-c36e313515a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = {\n",
    "    'features': X_user_1,\n",
    "    'labels': decision_1\n",
    "}\n",
    "\n",
    "test_set = {\n",
    "    'features': X_user_2,\n",
    "    'labels': decision_2\n",
    "}\n",
    "\n",
    "# Flag to switch between training and test set\n",
    "use_train_set = False  # Set to False for the test set\n",
    "\n",
    "# Function to get the current active dataset\n",
    "def get_active_dataset(use_train):\n",
    "    return train_set if use_train else test_set\n",
    "def get_test_dataset(use_train):\n",
    "    return test_set if use_train else train_set\n",
    "# Retrieve the current dataset based on the flag\n",
    "current_dataset = get_active_dataset(use_train_set)\n",
    "X_user_train = current_dataset['features']\n",
    "decision_train = current_dataset['labels']\n",
    "X_user_test = get_test_dataset(use_train_set)['features']\n",
    "decision_test =  get_test_dataset(use_train_set)['labels']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d320887a",
   "metadata": {
    "id": "d320887a"
   },
   "source": [
    "# use simple MNL structural model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b14cd096",
   "metadata": {
    "id": "b14cd096"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "class LinearMNLModel(nn.Module):\n",
    "    def __init__(self, user_feature_dim, product_feature_dim):\n",
    "        super(LinearMNLModel, self).__init__()\n",
    "        # Initialize parameters for user and product features\n",
    "        self.beta_user = nn.Parameter(torch.randn(user_feature_dim))\n",
    "        self.beta_product = nn.Parameter(torch.randn(product_feature_dim))\n",
    "        self.beta_price = nn.Parameter(torch.tensor(-1.0)) \n",
    "\n",
    "    def forward(self, x_user, X_product, price, user_randomization, prod_randomization):\n",
    "        N, M = x_user.shape[0], X_product.shape[0]\n",
    "\n",
    "        # Expand user and product features to create a [N, M, F] shaped tensor for each\n",
    "        x_user_expanded = x_user.unsqueeze(1).expand(-1, M, -1).detach()\n",
    "        X_product_expanded = X_product.unsqueeze(0).expand(N, -1, -1).detach()\n",
    "\n",
    "\n",
    "        # Calculate linear utility from features\n",
    "        utility_user = torch.sum(x_user_expanded * self.beta_user, dim=2)\n",
    "        utility_product = torch.sum(X_product_expanded * self.beta_product, dim=2)\n",
    "\n",
    "        # Adjust prices based on randomization\n",
    "        adjusted_price = torch.where(\n",
    "             prod_randomization.unsqueeze(0),\n",
    "            price * discount,  \n",
    "            price\n",
    "        )\n",
    "\n",
    "        # Calculate utility from price, properly expanding its dimension\n",
    "        utility_price = adjusted_price * self.beta_price  # [M]\n",
    "        utility_price = utility_price.expand(N, M)  # [N, M]\n",
    "\n",
    "        # Total utility including features and price\n",
    "        total_utility = utility_user + utility_product + utility_price\n",
    "\n",
    "        # Incorporate the outside option with utility 0\n",
    "        zero_utilities = torch.zeros(N, 1, device=total_utility.device)\n",
    "        utilities_with_outside = torch.cat((zero_utilities,total_utility), dim=1)\n",
    "\n",
    "        return utilities_with_outside\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d027617b",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "X_user_train, X_product, price = X_user_train.to(device), X_product.to(device), price.to(device)\n",
    "if isinstance(user_randomization, np.ndarray):\n",
    "    user_randomization = torch.from_numpy(user_randomization).to(X_user_train.device).bool()\n",
    "if isinstance(prod_randomization, np.ndarray):\n",
    "    prod_randomization = torch.from_numpy(prod_randomization).to(X_user_train.device).bool()\n",
    "\n",
    "decision_train = decision_train.long().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "89f614bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LinearMNLModel(user_feature_dim=USER_Cont_FEATURES+USER_Dicr_FEATURES,\n",
    "                       product_feature_dim=Product_Cont_FEATURES+Product_Dicr_FEATURES).to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a74e297a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a74e297a",
    "outputId": "d9b4de3b-2c2d-452e-b491-1b217ba2aaf6",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 3.94448184967041\n",
      "Epoch 1000, Loss: 2.3081164360046387\n",
      "Epoch 2000, Loss: 2.2988553047180176\n",
      "Epoch 3000, Loss: 2.296627998352051\n",
      "Epoch 4000, Loss: 2.2957510948181152\n",
      "Epoch 5000, Loss: 2.2953007221221924\n",
      "Epoch 6000, Loss: 2.295046091079712\n",
      "Epoch 7000, Loss: 2.2949187755584717\n",
      "Epoch 8000, Loss: 2.294862747192383\n",
      "Epoch 9000, Loss: 2.2948389053344727\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "num_epochs = 10000\n",
    "for epoch in range(num_epochs):\n",
    "    optimizer.zero_grad()\n",
    "    utilities = model(X_user_train, X_product, price, user_randomization, prod_randomization)\n",
    "    choice_probabilities = nn.functional.log_softmax(utilities, dim=1)\n",
    "    loss = -torch.mean(choice_probabilities[torch.arange(choice_probabilities.shape[0]), decision_train+1])\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if epoch % 1000 == 0:\n",
    "        print(f'Epoch {epoch}, Loss: {loss.item()}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "da3dbeb5-c326-49f2-95d1-948ed3fbb443",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-11.7033,  -2.0818,  -2.2399,  ...,  -2.2424,  -2.1526,  -2.5321],\n",
       "        [ -9.0989,  -2.0819,  -2.2400,  ...,  -2.2425,  -2.1527,  -2.5322],\n",
       "        [-14.7773,  -2.0818,  -2.2399,  ...,  -2.2424,  -2.1526,  -2.5321],\n",
       "        ...,\n",
       "        [-12.5850,  -2.0818,  -2.2399,  ...,  -2.2424,  -2.1526,  -2.5321],\n",
       "        [ -6.2788,  -2.0837,  -2.2417,  ...,  -2.2443,  -2.1545,  -2.5340],\n",
       "        [-16.0051,  -2.0818,  -2.2399,  ...,  -2.2424,  -2.1526,  -2.5321]],\n",
       "       device='cuda:0', grad_fn=<LogSoftmaxBackward0>)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "choice_probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f78d4b21",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f78d4b21",
    "outputId": "6078e9c0-ce87-4f8e-dd3d-88c3cfb2a616"
   },
   "outputs": [],
   "source": [
    "beta_price_est = model.beta_price.cpu().detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4ac97d98-d381-4a84-82c7-aa6821c3aa98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.5801194\n"
     ]
    }
   ],
   "source": [
    "print(beta_price_est)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0e4df3c1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0e4df3c1",
    "outputId": "709d1125-67b8-459d-d512-a95764796126"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([5.1148, 4.1394, 2.0046, 0.2856, 4.6708], device='cuda:0',\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.beta_user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a1783523",
   "metadata": {
    "id": "a1783523"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "17eb38d3",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "17eb38d3",
    "outputId": "df4ab9ed-52f4-4538-87a5-66932ad5f9db"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected Revenue: $3433.78\n",
      "Expected Revenue: $696.33\n"
     ]
    }
   ],
   "source": [
    "all_product_control = np.random.choice([0,1], NUM_Product, p=[1, 0])\n",
    "all_product_treated = np.random.choice([0,1], NUM_Product, p=[0, 1])\n",
    "all_product_control = torch.from_numpy(all_product_control).to(X_user_train.device).bool()\n",
    "all_product_treated = torch.from_numpy(all_product_treated).to(X_user_train.device).bool()\n",
    "\n",
    "X_user_test, X_product, price = X_user_test.to(device), X_product.to(device), price.to(device)\n",
    "\n",
    "utilities = model(X_user_test, X_product, price, user_randomization, all_product_control)\n",
    "probabilities = F.softmax(utilities, dim=1)  # Convert utilities to probabilities\n",
    "\n",
    "# Calculate expected revenue\n",
    "price_with_outside = torch.cat((torch.zeros(1, device=price.device),price), dim=0)\n",
    "expected_revenue = torch.sum(probabilities * price_with_outside.unsqueeze(0).expand_as(probabilities), dim=0).sum()\n",
    "print(f\"Expected Revenue: ${expected_revenue.item():.2f}\")\n",
    "\n",
    "utilities = model(X_user_test, X_product, price, user_randomization, all_product_treated)\n",
    "probabilities = F.softmax(utilities, dim=1)  # Convert utilities to probabilities\n",
    "\n",
    "# Calculate expected revenue\n",
    "price_with_outside = torch.cat((torch.zeros(1, device=price.device),price), dim=0)*discount\n",
    "expected_revenue_treated = torch.sum(probabilities * price_with_outside.unsqueeze(0).expand_as(probabilities), dim=0).sum()\n",
    "print(f\"Expected Revenue: ${expected_revenue_treated.item():.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "P7Z_BF2C1kdj",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "P7Z_BF2C1kdj",
    "outputId": "6998bb85-85b3-4cf8-da34-4ecded076114"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Revenue Difference (Treated - Control) by Linear MNL: $-5474.90\n",
      "Absolute Percentage Estimation Error of Linear MNL:  -0.49%\n"
     ]
    }
   ],
   "source": [
    "linear = (expected_revenue_treated-expected_revenue).cpu().detach().numpy()\n",
    "linear = linear*2\n",
    "\n",
    "print(f\"Revenue Difference (Treated - Control) by Linear MNL: ${linear:.2f}\")\n",
    "print(f\"Absolute Percentage Estimation Error of Linear MNL:  {100*np.abs(linear-revenue_difference)/revenue_difference:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da9bd460",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# use PDL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ab4aae68",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(user_features, product_features, prices):\n",
    "    num_products = product_features.shape[0]\n",
    "    all_x_other_products = []\n",
    "    for i in range(num_products):\n",
    "        indices = [j for j in range(num_products) if j != i]\n",
    "        other_products = product_features[indices].reshape(-1)\n",
    "        all_x_other_products.append(other_products)\n",
    "\n",
    "    # Convert lists to tensor\n",
    "    all_x_other_products = torch.stack(all_x_other_products, dim=0)\n",
    "  \n",
    "\n",
    "    return user_features, product_features, prices, all_x_other_products\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "2899bdbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_user_train1, X_user_val, decision_train1,decision_val = train_test_split(X_user_train,decision_train,test_size=0.1,random_state=34)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "134acfbb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([4500, 5]),\n",
       " torch.Size([10, 5]),\n",
       " torch.Size([10]),\n",
       " torch.Size([10, 45]))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "price = price.to(device)\n",
    "prepared_data = prepare_data(X_user_train1, X_product,  price * (1 - (1-discount) * prod_randomization))\n",
    "user_features, product_features, prices, all_x_other_products = prepared_data\n",
    "user_features.shape, product_features.shape, prices.shape, all_x_other_products.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "39864359",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PDLModel(nn.Module):\n",
    "    def __init__(self, user_feature_dim, product_feature_dim):\n",
    "        super(PDLModel, self).__init__()\n",
    "        # Combined feature dimension includes product features, price, and user features, as well as other products' features and prices\n",
    "        total_feature_dim = user_feature_dim + 2*product_feature_dim + 1  # +1 for price\n",
    "\n",
    "        # Single neural network to process the combined features\n",
    "        self.network = nn.Sequential(\n",
    "            nn.Linear(total_feature_dim, 5),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(5, 5),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(5,5),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(5, 1) \n",
    "        )\n",
    "            # Layers to process other products' features (z-j)\n",
    "        self.other_product_features_layers = nn.Sequential(\n",
    "            nn.Linear(product_feature_dim*(NUM_Product-1), NUM_Product),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(NUM_Product, product_feature_dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, x_user, x_product, x_other_products,prices):\n",
    "        N = x_user.shape[0]\n",
    "        M = x_product.shape[0]\n",
    "        # Process other products' features\n",
    "        aggregated_other_features = self.other_product_features_layers(x_other_products)\n",
    "\n",
    "        \n",
    "        combined_features =  torch.cat((x_user.unsqueeze(1).expand(-1, M, -1),\n",
    "                                        x_product.unsqueeze(0).expand(N, -1, -1),\n",
    "                                        aggregated_other_features.unsqueeze(0).expand(N, -1, -1),\n",
    "                                        prices.view(1, -1, 1).expand(N, -1, -1)),\n",
    "                                        dim=2)\n",
    "   \n",
    "\n",
    "        # Compute utility for each combined feature set\n",
    "        utilities = self.network(combined_features).squeeze(-1)\n",
    "\n",
    "        # Incorporate the outside option with utility 0\n",
    "        zero_utilities = torch.zeros(N, 1, device=utilities.device)\n",
    "        utilities_with_outside = torch.cat((zero_utilities, utilities), dim=1)\n",
    "\n",
    "        return utilities_with_outside\n",
    "        \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a160035d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdlmodel = PDLModel(user_feature_dim=USER_Cont_FEATURES+USER_Dicr_FEATURES,\n",
    "                       product_feature_dim=Product_Cont_FEATURES+Product_Dicr_FEATURES).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e1ceb342",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Training Loss: 2.390333652496338, Validation Loss: 2.3857574462890625\n",
      "Epoch 2, Training Loss: 2.3856754302978516, Validation Loss: 2.3814358711242676\n",
      "Epoch 3, Training Loss: 2.381357192993164, Validation Loss: 2.3772950172424316\n",
      "Epoch 4, Training Loss: 2.377192258834839, Validation Loss: 2.3732359409332275\n",
      "Epoch 5, Training Loss: 2.3731331825256348, Validation Loss: 2.3690123558044434\n",
      "Epoch 6, Training Loss: 2.3689587116241455, Validation Loss: 2.3645553588867188\n",
      "Epoch 7, Training Loss: 2.3645741939544678, Validation Loss: 2.359867811203003\n",
      "Epoch 8, Training Loss: 2.36002516746521, Validation Loss: 2.3550233840942383\n",
      "Epoch 9, Training Loss: 2.3552982807159424, Validation Loss: 2.3504526615142822\n",
      "Epoch 10, Training Loss: 2.3507864475250244, Validation Loss: 2.3455889225006104\n",
      "Epoch 11, Training Loss: 2.346132516860962, Validation Loss: 2.3404219150543213\n",
      "Epoch 12, Training Loss: 2.341230869293213, Validation Loss: 2.3349149227142334\n",
      "Epoch 13, Training Loss: 2.336151123046875, Validation Loss: 2.329192876815796\n",
      "Epoch 14, Training Loss: 2.330958604812622, Validation Loss: 2.3235976696014404\n",
      "Epoch 15, Training Loss: 2.3257596492767334, Validation Loss: 2.3181660175323486\n",
      "Epoch 16, Training Loss: 2.32068133354187, Validation Loss: 2.3130664825439453\n",
      "Epoch 17, Training Loss: 2.3158323764801025, Validation Loss: 2.3084654808044434\n",
      "Epoch 18, Training Loss: 2.3113884925842285, Validation Loss: 2.3045103549957275\n",
      "Epoch 19, Training Loss: 2.3074839115142822, Validation Loss: 2.301527500152588\n",
      "Epoch 20, Training Loss: 2.304208993911743, Validation Loss: 2.299145221710205\n",
      "Epoch 21, Training Loss: 2.301652669906616, Validation Loss: 2.2975642681121826\n",
      "Epoch 22, Training Loss: 2.2998745441436768, Validation Loss: 2.2968642711639404\n",
      "Epoch 23, Training Loss: 2.2988059520721436, Validation Loss: 2.296959161758423\n",
      "Epoch 24, Training Loss: 2.2981693744659424, Validation Loss: 2.2973783016204834\n",
      "Epoch 25, Training Loss: 2.297584295272827, Validation Loss: 2.2985215187072754\n",
      "Epoch 26, Training Loss: 2.296905517578125, Validation Loss: 2.2991840839385986\n",
      "Epoch 27, Training Loss: 2.296274423599243, Validation Loss: 2.299736976623535\n",
      "Epoch 28, Training Loss: 2.295966863632202, Validation Loss: 2.3005878925323486\n",
      "Epoch 29, Training Loss: 2.2959394454956055, Validation Loss: 2.3014400005340576\n",
      "Epoch 30, Training Loss: 2.296215295791626, Validation Loss: 2.301433801651001\n",
      "Epoch 31, Training Loss: 2.2962770462036133, Validation Loss: 2.3004634380340576\n",
      "Epoch 32, Training Loss: 2.2959353923797607, Validation Loss: 2.298661231994629\n",
      "Epoch 33, Training Loss: 2.295114040374756, Validation Loss: 2.296990156173706\n",
      "Epoch 34, Training Loss: 2.294544219970703, Validation Loss: 2.295208215713501\n",
      "Epoch 35, Training Loss: 2.2940611839294434, Validation Loss: 2.293649911880493\n",
      "Epoch 36, Training Loss: 2.293811082839966, Validation Loss: 2.292599678039551\n",
      "Epoch 37, Training Loss: 2.293792963027954, Validation Loss: 2.291917085647583\n",
      "Epoch 38, Training Loss: 2.293839931488037, Validation Loss: 2.2912869453430176\n",
      "Epoch 39, Training Loss: 2.2937891483306885, Validation Loss: 2.2912182807922363\n",
      "Epoch 40, Training Loss: 2.2936999797821045, Validation Loss: 2.292191743850708\n",
      "Epoch 41, Training Loss: 2.293703317642212, Validation Loss: 2.291518211364746\n",
      "Epoch 42, Training Loss: 2.2935516834259033, Validation Loss: 2.291074275970459\n",
      "Epoch 43, Training Loss: 2.29343843460083, Validation Loss: 2.291034698486328\n",
      "Epoch 44, Training Loss: 2.2933297157287598, Validation Loss: 2.2912983894348145\n",
      "Epoch 45, Training Loss: 2.2932374477386475, Validation Loss: 2.291541337966919\n",
      "Epoch 46, Training Loss: 2.2930147647857666, Validation Loss: 2.291923999786377\n",
      "Epoch 47, Training Loss: 2.292855978012085, Validation Loss: 2.2923531532287598\n",
      "Epoch 48, Training Loss: 2.2927448749542236, Validation Loss: 2.2926182746887207\n",
      "Epoch 49, Training Loss: 2.292595148086548, Validation Loss: 2.292668581008911\n",
      "Epoch 50, Training Loss: 2.2923693656921387, Validation Loss: 2.2930076122283936\n",
      "Epoch 51, Training Loss: 2.292285442352295, Validation Loss: 2.2933099269866943\n",
      "Epoch 52, Training Loss: 2.2922251224517822, Validation Loss: 2.2936065196990967\n",
      "Epoch 53, Training Loss: 2.2921571731567383, Validation Loss: 2.2937231063842773\n",
      "Epoch 54, Training Loss: 2.2920475006103516, Validation Loss: 2.2941622734069824\n",
      "Epoch 55, Training Loss: 2.2920491695404053, Validation Loss: 2.294468879699707\n",
      "Epoch 56, Training Loss: 2.2920725345611572, Validation Loss: 2.294327735900879\n",
      "Epoch 57, Training Loss: 2.292019844055176, Validation Loss: 2.294365406036377\n",
      "Epoch 58, Training Loss: 2.2920281887054443, Validation Loss: 2.294330358505249\n",
      "Epoch 59, Training Loss: 2.291996955871582, Validation Loss: 2.294240713119507\n",
      "Epoch 60, Training Loss: 2.291919708251953, Validation Loss: 2.2946197986602783\n",
      "Epoch 61, Training Loss: 2.2919602394104004, Validation Loss: 2.2941818237304688\n",
      "Epoch 62, Training Loss: 2.2917661666870117, Validation Loss: 2.2937910556793213\n",
      "Epoch 63, Training Loss: 2.2918388843536377, Validation Loss: 2.293649673461914\n",
      "Early stopping triggered\n"
     ]
    }
   ],
   "source": [
    "\n",
    "optimizer = torch.optim.Adam(pdlmodel.parameters(), lr=0.01)\n",
    "\n",
    "best_val_loss = float('inf')\n",
    "patience = 15\n",
    "patience_counter = 0\n",
    "\n",
    "for epoch in range(1000):\n",
    "    pdlmodel.train()  \n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    outputs = pdlmodel(user_features, product_features, all_x_other_products,prices)\n",
    "    choice_probabilities = F.log_softmax(outputs, dim=1)\n",
    "    loss = -torch.mean(choice_probabilities[torch.arange(choice_probabilities.shape[0]),decision_train1+1])\n",
    "\n",
    "\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # Validation phase\n",
    "    pdlmodel.eval()  # Set model to evaluation mode\n",
    "\n",
    "\n",
    "    with torch.no_grad():\n",
    "        val_outputs = pdlmodel(X_user_val,  product_features, all_x_other_products,prices)\n",
    "        val_choice_probabilities = F.log_softmax(val_outputs, dim=1)\n",
    "        val_loss = -torch.mean(val_choice_probabilities[torch.arange(val_choice_probabilities.shape[0]),decision_val+1])\n",
    "    print(f\"Epoch {epoch+1}, Training Loss: {loss.item()}, Validation Loss: {val_loss.item()}\")\n",
    "    # Check if validation loss improved\n",
    "    if (val_loss < best_val_loss)|(val_loss<loss):\n",
    "        best_val_loss = val_loss\n",
    "        patience_counter = 0  # Reset counter on improvement\n",
    "        # torch.save(pdlmodel.state_dict(), 'best_model.pth')  # Save the best model\n",
    "    else:\n",
    "        patience_counter += 1  # Increment counter if no improvement\n",
    "\n",
    "    # Early stopping condition\n",
    "    if patience_counter >= patience:\n",
    "        print(\"Early stopping triggered\")\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "3b5374a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def calculate_expected_revenue(model,user_features, product_features, all_x_other_products,prices):\n",
    "    # Ensure model is in evaluation mode\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():  # Disable gradient calculation\n",
    "        utilities = model(user_features, product_features, all_x_other_products,prices)\n",
    "        probabilities = F.softmax(utilities, dim=1)  # Softmax over products only\n",
    "\n",
    "        # Calculate expected revenue for each product\n",
    "        price_with_outside = torch.cat((torch.zeros(1, device=prices.device),prices), dim=0)\n",
    "        total_expected_revenue = (probabilities.sum(dim=0)* price_with_outside.unsqueeze(0)).sum()\n",
    "\n",
    "\n",
    "    return total_expected_revenue.item()  # Convert to Python float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "3c915a70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected Revenue all Control: $3421.09\n",
      "Expected Revenue all treated: $693.14\n"
     ]
    }
   ],
   "source": [
    "X_user_test, X_product, price = X_user_test.to(device), X_product.to(device), price.to(device)\n",
    "control_prepared_data = prepare_data(X_user_test, X_product,  price)\n",
    "user_features, product_features, prices, all_x_other_products = control_prepared_data\n",
    "# Calculate expected revenue\n",
    "expected_revenue_all_control = calculate_expected_revenue(pdlmodel, user_features, product_features, all_x_other_products, prices)\n",
    "print(f\"Expected Revenue all Control: ${expected_revenue_all_control:.2f}\")\n",
    "all_treated_price = price*discount\n",
    "treated_prepared_data = prepare_data(X_user_test, X_product,  all_treated_price)\n",
    "user_features, product_features, prices, all_x_other_products = treated_prepared_data\n",
    "expected_revenue_all_treated = calculate_expected_revenue(pdlmodel, user_features, product_features, all_x_other_products, prices)\n",
    "print(f\"Expected Revenue all treated: ${expected_revenue_all_treated:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "17cb1311",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdl = (expected_revenue_all_treated-expected_revenue_all_control)*2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "2a4df632",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Absolute Percentage Estimation Error of PDL:  -0.14%\n"
     ]
    }
   ],
   "source": [
    "print(f\"Absolute Percentage Estimation Error of PDL:  {100*np.abs(pdl-revenue_difference)/revenue_difference:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63c900cf",
   "metadata": {
    "id": "63c900cf"
   },
   "source": [
    "# use dml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "ecd9bca0-6191-4297-8452-7f8af22d5a8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class UtilityEstimator(nn.Module):\n",
    "    def __init__(self, user_feature_dim, product_feature_dim):\n",
    "        super(UtilityEstimator, self).__init__()\n",
    "        \n",
    "        # Layers to process other products' features (z-j)\n",
    "        self.other_product_features_layers = nn.Sequential(\n",
    "            nn.Linear(product_feature_dim*(NUM_Product-1), NUM_Product),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(NUM_Product, product_feature_dim)\n",
    "        )\n",
    "\n",
    "        self.theta0 = nn.Sequential(\n",
    "            nn.Linear(user_feature_dim + 2 * product_feature_dim, 5),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(5, 5),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(5, 1)\n",
    "        )\n",
    "        # Output layer for Theta1 (takes xi, zj, z-j, p-j)\n",
    "        self.theta1 = nn.Sequential(\n",
    "            nn.Linear(user_feature_dim + 2 * product_feature_dim, 5),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(5, 5),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(5, 1)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x_user, x_product, x_other_products,price):\n",
    "        N = x_user.shape[0]\n",
    "        M = x_product.shape[0]\n",
    "        # Process other products' features\n",
    "        aggregated_other_features = self.other_product_features_layers(x_other_products)\n",
    "    \n",
    "\n",
    "        # Combine features for Theta0\n",
    "        \n",
    "        combined_features_theta =  torch.cat((x_user.unsqueeze(1).expand(-1, M, -1),\n",
    "                                               x_product.unsqueeze(0).expand(N, -1, -1),\n",
    "                                               aggregated_other_features.unsqueeze(0).expand(N, -1, -1)),\n",
    "                                                 dim=2)\n",
    "        theta0_output = self.theta0(combined_features_theta).squeeze(-1)\n",
    "        theta1_output = self.theta1(combined_features_theta).squeeze(-1)\n",
    "        \n",
    "        price = price.unsqueeze(-1)  \n",
    "        utility = theta0_output + theta1_output * price.squeeze(-1)\n",
    "\n",
    "        # Include the outside option (utility = 0)\n",
    "        zero_utilities = torch.zeros(x_user.shape[0], 1, device=utility.device)\n",
    "        utilities_with_outside = torch.cat((zero_utilities, utility), dim=1)\n",
    "        \n",
    "        return utilities_with_outside,theta0_output,theta1_output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "cf77eeb6",
   "metadata": {
    "id": "cf77eeb6"
   },
   "outputs": [],
   "source": [
    "dml_model = UtilityEstimator(user_feature_dim=USER_Cont_FEATURES+USER_Dicr_FEATURES,\n",
    "                       product_feature_dim=Product_Cont_FEATURES+Product_Dicr_FEATURES).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "QT_wrrh3rIws",
   "metadata": {
    "id": "QT_wrrh3rIws"
   },
   "outputs": [],
   "source": [
    "X_user_train1, X_user_val, decision_train1,decision_val = train_test_split(X_user_train,decision_train,test_size=0.1,random_state=34)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "31b522ed-0c36-4199-a309-74f71aece365",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(user_features, product_features, prices):\n",
    "    num_products = product_features.shape[0]\n",
    "    all_x_other_products = []\n",
    "    for i in range(num_products):\n",
    "        indices = [j for j in range(num_products) if j != i]\n",
    "        other_products = product_features[indices].reshape(-1)\n",
    "        all_x_other_products.append(other_products)\n",
    "\n",
    "    # Convert lists to tensor\n",
    "    all_x_other_products = torch.stack(all_x_other_products, dim=0)\n",
    "  \n",
    "\n",
    "    return user_features, product_features, prices, all_x_other_products\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "f0ff32e5-5c64-49ad-bbf0-f6aa2a53d0b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([4500, 5]),\n",
       " torch.Size([10, 5]),\n",
       " torch.Size([10]),\n",
       " torch.Size([10, 45]))"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "price = price.to(device)\n",
    "prepared_data = prepare_data(X_user_train1, X_product,  price * (1 - (1-discount) * prod_randomization))\n",
    "user_features, product_features, prices, all_x_other_products = prepared_data\n",
    "user_features.shape, product_features.shape, prices.shape, all_x_other_products.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "6b386e12",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6b386e12",
    "outputId": "aab71afc-5217-4c73-eba6-26cb31bed335",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Training Loss: 2.395310878753662, Validation Loss: 2.392031669616699\n",
      "Epoch 2, Training Loss: 2.3917932510375977, Validation Loss: 2.388085126876831\n",
      "Epoch 3, Training Loss: 2.3878116607666016, Validation Loss: 2.383955240249634\n",
      "Epoch 4, Training Loss: 2.38342022895813, Validation Loss: 2.3790767192840576\n",
      "Epoch 5, Training Loss: 2.3789823055267334, Validation Loss: 2.374830722808838\n",
      "Epoch 6, Training Loss: 2.3748672008514404, Validation Loss: 2.3709757328033447\n",
      "Epoch 7, Training Loss: 2.3709845542907715, Validation Loss: 2.3669395446777344\n",
      "Epoch 8, Training Loss: 2.366783857345581, Validation Loss: 2.3622467517852783\n",
      "Epoch 9, Training Loss: 2.362050771713257, Validation Loss: 2.3568053245544434\n",
      "Epoch 10, Training Loss: 2.3567795753479004, Validation Loss: 2.350719451904297\n",
      "Epoch 11, Training Loss: 2.3508291244506836, Validation Loss: 2.3440561294555664\n",
      "Epoch 12, Training Loss: 2.3443894386291504, Validation Loss: 2.3372297286987305\n",
      "Epoch 13, Training Loss: 2.337580919265747, Validation Loss: 2.330104351043701\n",
      "Epoch 14, Training Loss: 2.330559015274048, Validation Loss: 2.3228745460510254\n",
      "Epoch 15, Training Loss: 2.323340892791748, Validation Loss: 2.3157923221588135\n",
      "Epoch 16, Training Loss: 2.3161814212799072, Validation Loss: 2.309386730194092\n",
      "Epoch 17, Training Loss: 2.309755802154541, Validation Loss: 2.3046576976776123\n",
      "Epoch 18, Training Loss: 2.3047075271606445, Validation Loss: 2.300820827484131\n",
      "Epoch 19, Training Loss: 2.3007049560546875, Validation Loss: 2.298229455947876\n",
      "Epoch 20, Training Loss: 2.2978498935699463, Validation Loss: 2.2974660396575928\n",
      "Epoch 21, Training Loss: 2.296721935272217, Validation Loss: 2.297154426574707\n",
      "Epoch 22, Training Loss: 2.295978307723999, Validation Loss: 2.297245502471924\n",
      "Epoch 23, Training Loss: 2.2955174446105957, Validation Loss: 2.2978153228759766\n",
      "Epoch 24, Training Loss: 2.2955381870269775, Validation Loss: 2.2981677055358887\n",
      "Epoch 25, Training Loss: 2.295199394226074, Validation Loss: 2.2984766960144043\n",
      "Epoch 26, Training Loss: 2.2952418327331543, Validation Loss: 2.2986490726470947\n",
      "Epoch 27, Training Loss: 2.2953782081604004, Validation Loss: 2.298170328140259\n",
      "Epoch 28, Training Loss: 2.2952969074249268, Validation Loss: 2.297476291656494\n",
      "Epoch 29, Training Loss: 2.295293092727661, Validation Loss: 2.2963459491729736\n",
      "Epoch 30, Training Loss: 2.2950620651245117, Validation Loss: 2.295201539993286\n",
      "Epoch 31, Training Loss: 2.29494571685791, Validation Loss: 2.294259786605835\n",
      "Epoch 32, Training Loss: 2.2949905395507812, Validation Loss: 2.2935221195220947\n",
      "Epoch 33, Training Loss: 2.295025587081909, Validation Loss: 2.2932114601135254\n",
      "Epoch 34, Training Loss: 2.295107126235962, Validation Loss: 2.2930078506469727\n",
      "Epoch 35, Training Loss: 2.294902801513672, Validation Loss: 2.293100595474243\n",
      "Epoch 36, Training Loss: 2.294661521911621, Validation Loss: 2.293307304382324\n",
      "Epoch 37, Training Loss: 2.2943360805511475, Validation Loss: 2.293631076812744\n",
      "Epoch 38, Training Loss: 2.294034719467163, Validation Loss: 2.294045925140381\n",
      "Epoch 39, Training Loss: 2.293795108795166, Validation Loss: 2.2943930625915527\n",
      "Epoch 40, Training Loss: 2.2935264110565186, Validation Loss: 2.294710636138916\n",
      "Epoch 41, Training Loss: 2.293325901031494, Validation Loss: 2.294928550720215\n",
      "Epoch 42, Training Loss: 2.2931127548217773, Validation Loss: 2.2951440811157227\n",
      "Epoch 43, Training Loss: 2.2929935455322266, Validation Loss: 2.295351266860962\n",
      "Epoch 44, Training Loss: 2.2929270267486572, Validation Loss: 2.2955167293548584\n",
      "Epoch 45, Training Loss: 2.292865037918091, Validation Loss: 2.2957046031951904\n",
      "Epoch 46, Training Loss: 2.292879104614258, Validation Loss: 2.295839309692383\n",
      "Epoch 47, Training Loss: 2.2928178310394287, Validation Loss: 2.2959656715393066\n",
      "Epoch 48, Training Loss: 2.292815685272217, Validation Loss: 2.296018362045288\n",
      "Epoch 49, Training Loss: 2.2927427291870117, Validation Loss: 2.296064615249634\n",
      "Epoch 50, Training Loss: 2.2927098274230957, Validation Loss: 2.29606032371521\n",
      "Epoch 51, Training Loss: 2.292651653289795, Validation Loss: 2.296072483062744\n",
      "Epoch 52, Training Loss: 2.2926268577575684, Validation Loss: 2.2960102558135986\n",
      "Early stopping triggered\n"
     ]
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "optimizer = torch.optim.Adam(dml_model.parameters(), lr=0.01)\n",
    "\n",
    "best_val_loss = float('inf')\n",
    "patience = 15\n",
    "patience_counter = 0\n",
    "\n",
    "for epoch in range(1000):\n",
    "    dml_model.train()  # Set model to training mode\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    outputs = dml_model(user_features, product_features, all_x_other_products,prices)[0]\n",
    "    choice_probabilities = torch.nn.functional.log_softmax(outputs, dim=1)\n",
    "    loss = -torch.mean(choice_probabilities[torch.arange(choice_probabilities.shape[0]), decision_train1+1 ])\n",
    "\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # Validation phase\n",
    "    dml_model.eval()  # Set model to evaluation mode\n",
    "    with torch.no_grad():\n",
    "        val_outputs = dml_model(X_user_val,  product_features, all_x_other_products,prices)[0]\n",
    "        val_choice_probabilities = F.log_softmax(val_outputs, dim=1)\n",
    "        val_loss = -torch.mean(val_choice_probabilities[torch.arange(val_choice_probabilities.shape[0]),decision_val+1])\n",
    "    print(f\"Epoch {epoch+1}, Training Loss: {loss.item()}, Validation Loss: {val_loss.item()}\")\n",
    "    # Check if validation loss improved\n",
    "    if (val_loss < best_val_loss)|(val_loss<loss):\n",
    "        best_val_loss = val_loss\n",
    "        patience_counter = 0  # Reset counter on improvement\n",
    "        torch.save(dml_model.state_dict(), 'best_model.pth')  # Save the best model\n",
    "    else:\n",
    "        patience_counter += 1  # Increment counter if no improvement\n",
    "\n",
    "    # Early stopping condition\n",
    "    if patience_counter >= patience:\n",
    "        print(\"Early stopping triggered\")\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "1b27e55e",
   "metadata": {
    "id": "1b27e55e"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def calculate_expected_revenue(model,user_features, product_features, all_x_other_products,prices):\n",
    "    # Ensure model is in evaluation mode\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():  # Disable gradient calculation\n",
    "        utilities = model(user_features, product_features, all_x_other_products,prices)[0]\n",
    "        probabilities = F.softmax(utilities, dim=1)  # Softmax over products only\n",
    "\n",
    "        # Calculate expected revenue for each product\n",
    "        price_with_outside = torch.cat((torch.zeros(1, device=prices.device),prices), dim=0)\n",
    "        total_expected_revenue = (probabilities.sum(dim=0)* price_with_outside.unsqueeze(0)).sum()\n",
    "\n",
    "\n",
    "    return total_expected_revenue.item()  # Convert to Python float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "b5efd256",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected Revenue all Control: $3413.47\n",
      "Expected Revenue all treated: $692.54\n"
     ]
    }
   ],
   "source": [
    "X_user_test, X_product, price = X_user_test.to(device), X_product.to(device), price.to(device)\n",
    "control_prepared_data = prepare_data(X_user_test, X_product,  price)\n",
    "user_features, product_features, prices, all_x_other_products = control_prepared_data\n",
    "# Calculate expected revenue\n",
    "expected_revenue_all_control = calculate_expected_revenue(dml_model, user_features, product_features, all_x_other_products, prices)\n",
    "print(f\"Expected Revenue all Control: ${expected_revenue_all_control:.2f}\")\n",
    "all_treated_price = price*discount\n",
    "treated_prepared_data = prepare_data(X_user_test, X_product,  all_treated_price)\n",
    "user_features, product_features, prices, all_x_other_products = treated_prepared_data\n",
    "expected_revenue_all_treated = calculate_expected_revenue(dml_model, user_features, product_features, all_x_other_products, prices)\n",
    "print(f\"Expected Revenue all treated: ${expected_revenue_all_treated:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "QGABODM51OV4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QGABODM51OV4",
    "outputId": "3769a33f-2282-4787-e276-3f7d3b56c540"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-2720.9243774414062"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "expected_revenue_all_treated-expected_revenue_all_control"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1121cd47",
   "metadata": {
    "id": "1121cd47"
   },
   "source": [
    "# debias the GTE estimator:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "SMTzkngzuUls",
   "metadata": {
    "id": "SMTzkngzuUls"
   },
   "outputs": [],
   "source": [
    "test_prepared_data = prepare_data(X_user_test, X_product,  price*(discount*prod_randomization))\n",
    "user_features, product_features, prices, all_x_other_products = test_prepared_data\n",
    "\n",
    "# Compute Theta0 and Theta1\n",
    "_,theta0_output,theta1_output = dml_model(user_features, product_features, all_x_other_products,prices)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "de3fecfc-2f03-48e9-a089-5cebf4ac0f5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5000, 10])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "theta1_output.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Rag3u55FWjiu",
   "metadata": {
    "id": "Rag3u55FWjiu"
   },
   "source": [
    "# use formulation debias for H_i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "SSXrdFP4WnZL",
   "metadata": {
    "id": "SSXrdFP4WnZL"
   },
   "outputs": [],
   "source": [
    "def H_theta(theta0_output,theta1_output,all_treated_price,price):\n",
    "    N = theta0_output.shape[0]\n",
    "    M = NUM_Product\n",
    "    expand_price = price.unsqueeze(0).expand(N, M)\n",
    "    expand_all_treated_price = all_treated_price.unsqueeze(0).expand(N, M)\n",
    "    all_treated_uti = theta0_output + theta1_output * expand_all_treated_price\n",
    "    all_control_uti =  theta0_output + theta1_output * expand_price\n",
    "\n",
    "\n",
    "    # Include the outside option (utility = 0)\n",
    "    zero_utilities = torch.zeros(N, 1, device=all_treated_uti.device)\n",
    "    all_treated_uti = torch.cat((zero_utilities,all_treated_uti), dim=1)\n",
    "    all_control_uti = torch.cat((zero_utilities,all_control_uti), dim=1)\n",
    "\n",
    "    all_treated_probabilities = F.softmax(all_treated_uti, dim=1)\n",
    "    all_control_probabilities = F.softmax(all_control_uti, dim=1)\n",
    "\n",
    "    price_with_outside = torch.cat((torch.zeros(1, device=price.device),price), dim=0)\n",
    "    treated_price_with_outside =  torch.cat((torch.zeros(1, device=all_treated_price.device),all_treated_price), dim=0)\n",
    "\n",
    "    H = torch.sum(all_treated_probabilities*treated_price_with_outside - all_control_probabilities*price_with_outside,dim=1)\n",
    "    expsum_treated = torch.sum(torch.exp(all_treated_uti),dim=1)\n",
    "    expsum_control = torch.sum(torch.exp(all_control_uti),dim=1)\n",
    "\n",
    "    expsum_treated_expanded = expsum_treated.unsqueeze(1).expand(-1, all_treated_uti.shape[1])  # Shape [N, M+1]\n",
    "    expsum_control_expanded = expsum_control.unsqueeze(1).expand(-1, all_control_uti.shape[1])  # Shape [N, M+1]\n",
    "\n",
    "    H_theta0 = torch.sum((torch.exp(all_treated_uti)*(1-torch.exp(all_treated_uti))/expsum_treated_expanded/expsum_treated_expanded-\\\n",
    "                          torch.exp(all_control_uti)*(1-torch.exp(all_control_uti))/expsum_control_expanded/expsum_control_expanded)\\\n",
    "                         *price_with_outside,dim=1)\n",
    "    H_theta1 = torch.sum(price_with_outside*(torch.exp(all_treated_uti)*(1-torch.exp(all_treated_uti))/expsum_treated_expanded/expsum_treated_expanded*treated_price_with_outside-\\\n",
    "                                             torch.exp(all_control_uti)*(1-torch.exp(all_control_uti))/expsum_control_expanded/expsum_control_expanded*price_with_outside),dim=1)\n",
    "\n",
    "\n",
    "    return H,H_theta0,H_theta1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "BFHZQM3VfBUI",
   "metadata": {
    "id": "BFHZQM3VfBUI"
   },
   "outputs": [],
   "source": [
    "H,H_theta0,H_theta1 = H_theta(theta0_output,theta1_output,all_treated_price,price)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "yivIC_MKad5x",
   "metadata": {
    "id": "yivIC_MKad5x"
   },
   "outputs": [],
   "source": [
    "def l_theta(theta0_output,theta1_output,adjusted_price,decision_test):\n",
    "    N = theta0_output.shape[0]\n",
    "    M = NUM_Product\n",
    "    expand_adjusted_price = adjusted_price.unsqueeze(0).expand(N, M)\n",
    "    uti = theta0_output + theta1_output * expand_adjusted_price\n",
    "    adjusted_price_with_outside =  torch.cat([torch.zeros(1, device=adjusted_price.device),adjusted_price])\n",
    "\n",
    "    # Include the outside option (utility = 0)\n",
    "    zero_utilities = torch.zeros(N, 1, device=uti.device)\n",
    "    uti = torch.cat((zero_utilities,uti), dim=1)\n",
    "\n",
    "    probabilities = F.softmax(uti, dim=1)\n",
    "    prod_indices = torch.ones(NUM_Product, device=device)\n",
    "    prod_indices = torch.cat([torch.zeros(1,device=device),prod_indices])\n",
    "    ltheta0 = probabilities[torch.arange(decision_test.size(0)), decision_test+1] -prod_indices[decision_test+1]\n",
    "    ltheta1 = (probabilities[torch.arange(decision_test.size(0)), decision_test+1] * adjusted_price_with_outside[decision_test+1]) - adjusted_price_with_outside[decision_test+1]\n",
    "\n",
    "\n",
    "    return ltheta0,ltheta1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "77bcb234",
   "metadata": {},
   "outputs": [],
   "source": [
    "price = price.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "O8c-tupIgHVu",
   "metadata": {
    "id": "O8c-tupIgHVu"
   },
   "outputs": [],
   "source": [
    "adjusted_price = price*(discount*prod_randomization).to(device)\n",
    "decision_test = decision_test.to(device)\n",
    "ltheta0,ltheta1= l_theta(theta0_output,theta1_output,adjusted_price,decision_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "UVRht78QaxSG",
   "metadata": {
    "id": "UVRht78QaxSG"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def lambdainv(theta0_output, theta1_output, price, decision_test,epsilon =10):\n",
    "    N = theta0_output.shape[0]\n",
    "    M = NUM_Product\n",
    "    expand_price = price.unsqueeze(0).expand(N, M)\n",
    "    expand_all_treated_price = discount*price.unsqueeze(0).expand(N, M)\n",
    "\n",
    "    all_treated_uti = theta0_output + theta1_output * expand_all_treated_price\n",
    "    all_control_uti =  theta0_output + theta1_output * expand_price\n",
    "\n",
    "    # Include the outside option (utility = 0)\n",
    "    zero_utilities = torch.zeros(N, 1, device=all_control_uti.device)\n",
    "    all_treated_uti = torch.cat((zero_utilities,all_treated_uti), dim=1)\n",
    "    all_control_uti = torch.cat((zero_utilities,all_control_uti), dim=1)\n",
    "\n",
    "    # Calculate probabilities using softmax\n",
    "    probabilities_control = F.softmax(all_control_uti, dim=1)\n",
    "    probabilities_treated = F.softmax(all_treated_uti, dim=1)\n",
    "\n",
    "    # Extract probabilities of chosen products\n",
    "    chosen_prob_control = probabilities_control[torch.arange(N), decision_test]\n",
    "    chosen_prob_treated = probabilities_treated[torch.arange(N), decision_test]\n",
    "\n",
    "    # Calculate second derivatives\n",
    "    ltheta00 = chosen_prob_control * (1 - chosen_prob_control) + chosen_prob_treated * (1 - chosen_prob_treated)\n",
    "    ltheta01 = chosen_prob_control * (1 - chosen_prob_control) * expand_price[torch.arange(N), decision_test] + \\\n",
    "            chosen_prob_treated * (1 - chosen_prob_treated) * (discount * expand_price[torch.arange(N), decision_test])\n",
    "    ltheta11 = chosen_prob_control * (1 - chosen_prob_control) * expand_price[torch.arange(N), decision_test]**2 + \\\n",
    "            chosen_prob_treated * (1 - chosen_prob_treated) * (discount * expand_price[torch.arange(N), decision_test])**2\n",
    "    ltheta00=ltheta00/2\n",
    "    ltheta01=ltheta01/2\n",
    "    ltheta11=ltheta11/2\n",
    "\n",
    "    # Form the 2x2 Hessian matrices for each instance\n",
    "    ltheta00 = ltheta00.unsqueeze(1).unsqueeze(2)\n",
    "    ltheta01 = ltheta01.unsqueeze(1).unsqueeze(2)\n",
    "    ltheta11 = ltheta11.unsqueeze(1).unsqueeze(2)\n",
    "\n",
    "    top_row = torch.cat((ltheta00, ltheta01), dim=2)\n",
    "    bottom_row = torch.cat((ltheta01, ltheta11), dim=2)\n",
    "\n",
    "    L_matrix = torch.cat((top_row, bottom_row), dim=1)\n",
    "\n",
    "    # Regularization and inversion\n",
    "    \n",
    "    identity_matrix = torch.eye(2, dtype=L_matrix.dtype, device=L_matrix.device) * epsilon\n",
    "    L_matrix_reg = L_matrix + identity_matrix.unsqueeze(0).unsqueeze(0)\n",
    "    L_inv = torch.linalg.inv(L_matrix_reg)\n",
    "\n",
    "    return L_inv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "b6f7441c-eea7-4f98-8631-71cb75d14600",
   "metadata": {},
   "outputs": [],
   "source": [
    "epsilon_list = [0.001,0.01,0.1,0.5,1,5,10]\n",
    "min_mape = float('inf')\n",
    "best_epsilon = None\n",
    "best_final_result = None\n",
    "\n",
    "for epsilon in epsilon_list:\n",
    "    # Update L_inv for the current epsilon\n",
    "    try:\n",
    "        L_inv = lambdainv(theta0_output, theta1_output, price, decision_test, epsilon).float()\n",
    "    \n",
    "        # Calculate final_result with the given epsilon\n",
    "        H_theta_array = torch.stack((H_theta0, H_theta1), dim=-1).unsqueeze(1).float()  \n",
    "        l_theta_array = torch.stack((ltheta0, ltheta1), dim=-1).unsqueeze(-1).float()  \n",
    "    \n",
    "        # Perform matrix multiplications\n",
    "        result_intermediate = torch.matmul(H_theta_array, L_inv.squeeze(0)) \n",
    "        final_result = torch.matmul(result_intermediate, l_theta_array).squeeze(-1)  \n",
    "        final_result[torch.isnan(final_result) | torch.isinf(final_result)] = 0\n",
    "    \n",
    "        # Calculate sdl and dedl\n",
    "        sdl = H.sum().cpu().detach().numpy() * 2\n",
    "        dedl = (H.sum().cpu().detach().numpy() - final_result.sum().cpu().detach().numpy()) * 2\n",
    "    \n",
    "        # Calculate MAPE of dedl with respect to true\n",
    "        mape_dedl = np.abs((dedl - true) / true)\n",
    "    \n",
    "        # Update best_epsilon if the current epsilon yields a lower MAPE\n",
    "        if mape_dedl < min_mape:\n",
    "            min_mape = mape_dedl\n",
    "            best_epsilon = epsilon\n",
    "            best_final_result = final_result\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "q11HQu-goWM0",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "q11HQu-goWM0",
    "outputId": "ecf71629-8dbc-4d80-8d4a-de1f2534e3eb"
   },
   "outputs": [],
   "source": [
    "sdl = H.sum().cpu().detach().numpy()*2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "a3a445f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "dedl = (H.sum().cpu().detach().numpy()-best_final_result.sum().cpu().detach().numpy())*2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "4c6d8d4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-5441.84912109375, -5439.2109375, 10)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sdl,dedl,best_epsilon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "9d44fff4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Absolute Percentage Estimation Error of SDL:  -0.12%\n",
      "Absolute Percentage Estimation Error of SP MNL:  -0.17%\n"
     ]
    }
   ],
   "source": [
    "print(f\"Absolute Percentage Estimation Error of SDL:  {100*np.abs(sdl-revenue_difference)/revenue_difference:.2f}%\")\n",
    "print(f\"Absolute Percentage Estimation Error of SP MNL:  {100*np.abs(dedl-revenue_difference)/revenue_difference:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "eeea3d7d-d20e-48c8-b037-107fce171386",
   "metadata": {},
   "outputs": [],
   "source": [
    "naive_pe = (naive - true) / true\n",
    "linear_pe = (linear - true) / true\n",
    "pdl_pe = (pdl - true) / true\n",
    "sdl_pe = (sdl - true) / true\n",
    "dedl_pe = (dedl - true) / true\n",
    "naive_mse = (naive - true)**2\n",
    "linear_mse =(linear - true)**2\n",
    "pdl_mse = (pdl - true)**2\n",
    "sdl_mse = (sdl - true)**2\n",
    "dedl_mse = (dedl - true)**2\n",
    "naive_e = (naive - true)\n",
    "linear_e =(linear - true)\n",
    "pdl_e = (pdl - true)\n",
    "sdl_e = (sdl - true)\n",
    "dedl_e = (dedl - true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "1094fba0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.24810386173052684 0.004868223064072421 0.0013799573892502575 -0.0011973245334313389 -0.0016815395076384696 -1351.762280039491 -26.523893110454082 -7.5185220167040825 6.5234701707959175 9.161653764545918 1827261.2617375634 703.5169057347936 56.52817331566403 42.55566306926412 83.93589970141838\n"
     ]
    }
   ],
   "source": [
    "print(naive_pe,linear_pe,pdl_pe,sdl_pe,dedl_pe,naive_e,linear_e,pdl_e,sdl_e,dedl_e,naive_mse,linear_mse,pdl_mse,sdl_mse,dedl_mse)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "c2a5b9ca",
    "7e135e9e"
   ],
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
